// Copyright 2016 Adam Perry. Dual-licensed MIT and Apache 2.0 (see LICENSE files for details).


pub mod client;
pub mod models;
mod nag;
pub mod webhooks;

use chrono::{DateTime, NaiveDate, NaiveDateTime, NaiveTime, UTC};
use diesel::prelude::*;
use diesel::pg::PgConnection;
use diesel::pg::upsert::*;
use diesel;

use DB_POOL;
use domain::github::*;
use domain::schema::*;
use error::DashResult;

use self::client::Client;
use self::models::{CommentFromJson, IssueFromJson, PullRequestFromJson};

lazy_static! {
    pub static ref GH: Client = Client::new();
}

pub fn most_recent_update() -> DashResult<DateTime<UTC>> {
    info!("finding most recent github updates");

    let default_date = NaiveDateTime::new(NaiveDate::from_ymd(2015, 5, 15),
                                          NaiveTime::from_hms(0, 0, 0));

    let conn = &*DB_POOL.get()?;

    let updated: NaiveDateTime = {
        use domain::schema::githubsync::dsl::*;
        githubsync.select(ran_at)
            .filter(successful.eq(true))
            .order(ran_at.desc())
            .first(conn)
            .unwrap_or(default_date)
    };

    Ok(DateTime::from_utc(updated, UTC))
}

pub fn record_successful_update(ingest_start: NaiveDateTime) -> DashResult<()> {
    let conn = &*DB_POOL.get()?;
    // insert a successful sync record
    use domain::schema::githubsync::dsl::*;
    let sync_record = GitHubSyncPartial {
        successful: true,
        ran_at: ingest_start,
        message: None,
    };

    diesel::insert(&sync_record).into(githubsync).execute(conn)?;
    Ok(())
}

pub fn ingest_since(repo: &str, start: DateTime<UTC>) -> DashResult<()> {
    info!("fetching all {} issues and comments since {}", repo, start);
    let issues = try!(GH.issues_since(repo, start));
    let mut comments = try!(GH.comments_since(repo, start));
    // make sure we process the new comments in creation order
    comments.sort_by_key(|c| c.created_at);

    let mut prs: Vec<PullRequestFromJson> = vec![];
    for issue in &issues {
        // sleep(Duration::from_millis(github::client::DELAY));
        if let Some(ref pr_info) = issue.pull_request {
            match GH.fetch_pull_request(pr_info) {
                Ok(pr) => prs.push(pr),
                Err(why) => {
                    error!("ERROR fetching PR info: {:?}", why);
                    break;
                }
            }
        }
    }

    debug!("num pull requests updated since {}: {:#?}",
           &start,
           prs.len());

    debug!("num issues updated since {}: {:?}", &start, issues.len());
    debug!("num comments updated since {}: {:?}",
           &start,
           comments.len());

    let conn = &*DB_POOL.get()?;
    debug!("let's insert some stuff in the database");


    // make sure we have all of the users to ensure referential integrity
    for issue in issues {
        let issue_number = issue.number;
        match handle_issue(conn, issue, repo) {
            Ok(()) => (),
            Err(why) => {
                error!("Error processing issue {}#{}: {:?}",
                       repo,
                       issue_number,
                       why)
            }
        }
    }

    // insert the comments
    for comment in comments {
        let comment_id = comment.id;
        match handle_comment(conn, comment, repo) {
            Ok(()) => (),
            Err(why) => {
                error!("Error processing comment {}#{}: {:?}",
                       repo,
                       comment_id,
                       why)
            }
        }
    }

    for pr in prs {
        let pr_number = pr.number;
        match handle_pr(conn, pr, repo) {
            Ok(()) => (),
            Err(why) => error!("Error processing PR {}#{}: {:?}", repo, pr_number, why),
        }
    }

    Ok(())
}

pub fn update_issue(repo: &str, number: i32) -> DashResult<()> {
    let issue = GH.fetch_issue(repo, number)?;
    let comments = GH.fetch_comments(repo, number)?;
    let conn = &*DB_POOL.get()?;

    handle_issue(conn, issue, repo)?;
    for comment in comments {
        handle_comment(conn, comment, repo)?;
    }

    Ok(())
}

pub fn update_pr(repo: &str, number: i32) -> DashResult<()> {
    let pr = GH.fetch_pr(repo, number)?;
    let conn = &*DB_POOL.get()?;

    handle_pr(conn, pr, repo)
}

pub fn handle_pr(conn: &PgConnection, pr: PullRequestFromJson, repo: &str) -> DashResult<()> {
    use domain::schema::pullrequest::dsl::*;
    if let Some(ref assignee) = pr.assignee {
        handle_user(conn, assignee)?;
    }

    let pr: PullRequest = pr.with_repo(repo);
    diesel::insert(&pr.on_conflict((repository, number), do_update().set(&pr)))
        .into(pullrequest).execute(conn)?;
    Ok(())
}

pub fn handle_comment(conn: &PgConnection, comment: CommentFromJson, repo: &str) -> DashResult<()> {
    handle_user(conn, &comment.user)?;

    let comment: IssueComment = comment.with_repo(repo)?;

    // We only want to run `nag::update_nags` on insert to avoid
    // double-processing commits, so we can't use upsert here
    if issuecomment::table.find(comment.id).get_result::<IssueComment>(conn).is_ok() {
        diesel::update(issuecomment::table.find(comment.id)).set(&comment)
            .execute(conn)?;
        Ok(())
    } else {
        diesel::insert(&comment).into(issuecomment::table).execute(conn)?;
        match nag::update_nags(&comment) {
            Ok(()) => Ok(()),
            Err(why) => {
                error!("Problem updating FCPs: {:?}", &why);
                Err(why)
            }
        }
    }
}

pub fn handle_issue(conn: &PgConnection, issue: IssueFromJson, repo: &str) -> DashResult<()> {
    // user handling
    handle_user(conn, &issue.user)?;
    if let Some(ref assignee) = issue.assignee {
        handle_user(conn, assignee)?;
    }
    if let Some(ref milestone) = issue.milestone {
        handle_user(conn, &milestone.creator)?;
    }

    let (i, milestone) = issue.with_repo(repo);

    if let Some(milestone) = milestone {
        diesel::insert(&milestone.on_conflict(milestone::id,
                                              do_update().set(&milestone)))
            .into(milestone::table).execute(conn)?;
    }

    // handle issue itself
    {
        use domain::schema::issue::dsl::*;
        diesel::insert(&i.on_conflict((repository, number), do_update().set(&i)))
            .into(issue).execute(conn)?;
    }

    Ok(())
}

pub fn handle_user(conn: &PgConnection, user: &GitHubUser) -> DashResult<()> {
    diesel::insert(&user.on_conflict(githubuser::id, do_update().set(user)))
        .into(githubuser::table).execute(conn)?;
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env;

    #[test]
    fn test_handle_user() {
        let db_url = env::var("DATABASE_URL")
            .expect("DATABASE_URL must be set");
        let conn = PgConnection::establish(&db_url)
            .expect(&format!("Error connecting to {}", db_url));

        let user = GitHubUser {id: -1, login: "A".to_string()};
        let query = githubuser::table.filter(githubuser::id.eq(user.id));

        // User should not exist
        assert_eq!(query.load::<GitHubUser>(&conn), Ok(vec![]));

        // User has been inserted
        handle_user(&conn, &user).expect("Unable to handle user!");
        assert_eq!(query.load::<GitHubUser>(&conn), Ok(vec![user.clone()]));

        // User has been inserted, but nothing changed
        handle_user(&conn, &user).expect("Unable to handle user!");
        assert_eq!(query.load::<GitHubUser>(&conn), Ok(vec![user.clone()]));

        // User has been inserted, but login has changed
        let new_user = GitHubUser {id: user.id, login: user.login + "_new"};
        handle_user(&conn, &new_user).expect("Unable to handle user!");
        assert_eq!(query.load::<GitHubUser>(&conn), Ok(vec![new_user.clone()]));

        // Clean up after ourselves
        diesel::delete(githubuser::table.filter(githubuser::id.eq(user.id)))
            .execute(&conn)
            .expect("Failed to clear database");
    }
}
